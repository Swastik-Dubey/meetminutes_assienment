{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "efe281fd5eec4651a0d773890b7573b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_39833f6e45bc4148a0533e04bf610f05",
              "IPY_MODEL_4ca1b0341ea845a19a087eead52a04c7",
              "IPY_MODEL_4e8d0df7852f469fa218561cb817ccd2"
            ],
            "layout": "IPY_MODEL_954424013c4446f49fe4bfc468b26a75"
          }
        },
        "39833f6e45bc4148a0533e04bf610f05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9a47f28801a481693311dda0b188633",
            "placeholder": "​",
            "style": "IPY_MODEL_459f2c0f64094b2eaec54fa3a07a5918",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "4ca1b0341ea845a19a087eead52a04c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca1ff3fa4caf46488ff6062541b0c27a",
            "max": 2324,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66e027a8f7c74f489391e1f76c80e657",
            "value": 2324
          }
        },
        "4e8d0df7852f469fa218561cb817ccd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97e95572c97a41c79909b7f5951fd803",
            "placeholder": "​",
            "style": "IPY_MODEL_d80cd7865cce4cbdbe6db1e328c23924",
            "value": " 2.32k/2.32k [00:00&lt;00:00, 34.9kB/s]"
          }
        },
        "954424013c4446f49fe4bfc468b26a75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9a47f28801a481693311dda0b188633": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "459f2c0f64094b2eaec54fa3a07a5918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca1ff3fa4caf46488ff6062541b0c27a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66e027a8f7c74f489391e1f76c80e657": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97e95572c97a41c79909b7f5951fd803": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d80cd7865cce4cbdbe6db1e328c23924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d67410f1f9c4a51add32030caddb6a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc12b9c69c134e01a17017f68f8a9670",
              "IPY_MODEL_17d0c1fd732f4380975da091fa9d9693",
              "IPY_MODEL_a927a27b8d764559b0b8350686ec0635"
            ],
            "layout": "IPY_MODEL_256e3fcf87a84373b1b700fbfaf489b5"
          }
        },
        "cc12b9c69c134e01a17017f68f8a9670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a42bd5792ac74664b52cd45e5a2f433d",
            "placeholder": "​",
            "style": "IPY_MODEL_7536a36078c148d0ad6f3e916efac846",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "17d0c1fd732f4380975da091fa9d9693": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2934b37c29704de6934500a578b3a245",
            "max": 1206,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dbf3c788f3d446b2af27f41f4fd08969",
            "value": 1206
          }
        },
        "a927a27b8d764559b0b8350686ec0635": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_702fcc635bb140cca51353b4948aaf70",
            "placeholder": "​",
            "style": "IPY_MODEL_0f71e629ff9543e4975a96ca1bbf4c36",
            "value": " 1.21k/1.21k [00:00&lt;00:00, 25.8kB/s]"
          }
        },
        "256e3fcf87a84373b1b700fbfaf489b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a42bd5792ac74664b52cd45e5a2f433d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7536a36078c148d0ad6f3e916efac846": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2934b37c29704de6934500a578b3a245": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbf3c788f3d446b2af27f41f4fd08969": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "702fcc635bb140cca51353b4948aaf70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f71e629ff9543e4975a96ca1bbf4c36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b28467e0ff84639a26f36f384481f8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27418eb1a0b940beaf41c9931f74659a",
              "IPY_MODEL_05079227593f4fc796051eb4bee43d8a",
              "IPY_MODEL_b139f6246ef94cdbb19cf23eafcf41b9"
            ],
            "layout": "IPY_MODEL_46eafb1ad5b84d3b8b69df3bb78e3034"
          }
        },
        "27418eb1a0b940beaf41c9931f74659a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0825a1c41a534fc3bcdc0fb9fc8b0e6f",
            "placeholder": "​",
            "style": "IPY_MODEL_253a17c4d2d74e248a4b367350fa185d",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "05079227593f4fc796051eb4bee43d8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2355e39f2a4c4be4ba457ee21848b304",
            "max": 242043056,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a3e3bb9955a14503b4a966fa75345c81",
            "value": 242043056
          }
        },
        "b139f6246ef94cdbb19cf23eafcf41b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8a8484b16734325a8b4f6f7268c9238",
            "placeholder": "​",
            "style": "IPY_MODEL_ea203ca856e948d0b3a46be377a82daf",
            "value": " 242M/242M [00:03&lt;00:00, 62.9MB/s]"
          }
        },
        "46eafb1ad5b84d3b8b69df3bb78e3034": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0825a1c41a534fc3bcdc0fb9fc8b0e6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "253a17c4d2d74e248a4b367350fa185d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2355e39f2a4c4be4ba457ee21848b304": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3e3bb9955a14503b4a966fa75345c81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d8a8484b16734325a8b4f6f7268c9238": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea203ca856e948d0b3a46be377a82daf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6afe534d4b9d41fe9e0eceba25c8625f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f7ecac901554e7e8f18c0b06adda6f1",
              "IPY_MODEL_ad88809b41554d40b4e1d69d17ad387a",
              "IPY_MODEL_125bef49133c483fa4ded0355fbbf0e4"
            ],
            "layout": "IPY_MODEL_1ec6c38fa5d5470dbe6429e9666180af"
          }
        },
        "3f7ecac901554e7e8f18c0b06adda6f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97a30ba9657041959ab5d6fcbe165120",
            "placeholder": "​",
            "style": "IPY_MODEL_09b440774ce14b9ba4a0f07665430835",
            "value": "Downloading (…)neration_config.json: 100%"
          }
        },
        "ad88809b41554d40b4e1d69d17ad387a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c910045cb02248e5880cf05c4e13694e",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05175c12b8814c3f86e07a823f601ff5",
            "value": 147
          }
        },
        "125bef49133c483fa4ded0355fbbf0e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71ea39d0dd254af28e09c8f5491af574",
            "placeholder": "​",
            "style": "IPY_MODEL_5b495c07adbc47ae847531e7b96cd357",
            "value": " 147/147 [00:00&lt;00:00, 4.00kB/s]"
          }
        },
        "1ec6c38fa5d5470dbe6429e9666180af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97a30ba9657041959ab5d6fcbe165120": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09b440774ce14b9ba4a0f07665430835": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c910045cb02248e5880cf05c4e13694e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05175c12b8814c3f86e07a823f601ff5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71ea39d0dd254af28e09c8f5491af574": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b495c07adbc47ae847531e7b96cd357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhtJHXYlp5FS"
      },
      "outputs": [],
      "source": [
        "!pip install transformers --upgrade\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDQHUF9NxcwL",
        "outputId": "8da7c798-c090-4521-c5ce-1bb0b9bb67ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# Initialize the tokenizer and model\n",
        "model_name = \"t5-small\"  # You can use \"t5-small\" or other variants\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312,
          "referenced_widgets": [
            "dfa10a222e2c4badb5d8620569d6fbe5",
            "efe281fd5eec4651a0d773890b7573b6",
            "39833f6e45bc4148a0533e04bf610f05",
            "4ca1b0341ea845a19a087eead52a04c7",
            "4e8d0df7852f469fa218561cb817ccd2",
            "954424013c4446f49fe4bfc468b26a75",
            "a9a47f28801a481693311dda0b188633",
            "459f2c0f64094b2eaec54fa3a07a5918",
            "ca1ff3fa4caf46488ff6062541b0c27a",
            "66e027a8f7c74f489391e1f76c80e657",
            "97e95572c97a41c79909b7f5951fd803",
            "d80cd7865cce4cbdbe6db1e328c23924",
            "1d67410f1f9c4a51add32030caddb6a5",
            "cc12b9c69c134e01a17017f68f8a9670",
            "17d0c1fd732f4380975da091fa9d9693",
            "a927a27b8d764559b0b8350686ec0635",
            "256e3fcf87a84373b1b700fbfaf489b5",
            "a42bd5792ac74664b52cd45e5a2f433d",
            "7536a36078c148d0ad6f3e916efac846",
            "2934b37c29704de6934500a578b3a245",
            "dbf3c788f3d446b2af27f41f4fd08969",
            "702fcc635bb140cca51353b4948aaf70",
            "0f71e629ff9543e4975a96ca1bbf4c36",
            "4b28467e0ff84639a26f36f384481f8c",
            "27418eb1a0b940beaf41c9931f74659a",
            "05079227593f4fc796051eb4bee43d8a",
            "b139f6246ef94cdbb19cf23eafcf41b9",
            "46eafb1ad5b84d3b8b69df3bb78e3034",
            "0825a1c41a534fc3bcdc0fb9fc8b0e6f",
            "253a17c4d2d74e248a4b367350fa185d",
            "2355e39f2a4c4be4ba457ee21848b304",
            "a3e3bb9955a14503b4a966fa75345c81",
            "d8a8484b16734325a8b4f6f7268c9238",
            "ea203ca856e948d0b3a46be377a82daf",
            "6afe534d4b9d41fe9e0eceba25c8625f",
            "3f7ecac901554e7e8f18c0b06adda6f1",
            "ad88809b41554d40b4e1d69d17ad387a",
            "125bef49133c483fa4ded0355fbbf0e4",
            "1ec6c38fa5d5470dbe6429e9666180af",
            "97a30ba9657041959ab5d6fcbe165120",
            "09b440774ce14b9ba4a0f07665430835",
            "c910045cb02248e5880cf05c4e13694e",
            "05175c12b8814c3f86e07a823f601ff5",
            "71ea39d0dd254af28e09c8f5491af574",
            "5b495c07adbc47ae847531e7b96cd357"
          ]
        },
        "id": "_zcH0t_EqAU0",
        "outputId": "42243f9d-3951-46d6-b92f-5b1bd1113618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dfa10a222e2c4badb5d8620569d6fbe5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "efe281fd5eec4651a0d773890b7573b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d67410f1f9c4a51add32030caddb6a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b28467e0ff84639a26f36f384481f8c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6afe534d4b9d41fe9e0eceba25c8625f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_excel('/content/Copy of Sample_Insights_from_MeetMinutes(1242).xlsx')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9qhpo0pWq5Fc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VTwIFLnciA3",
        "outputId": "c5d2e951-131f-434e-f6a6-4eb37fb322e2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['og_transcript', 'file_name', 'language', 'participant', 'output'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from transformers import T5Tokenizer\n",
        "\n",
        "# Initialize the T5 tokenizer\n",
        "model_name = \"t5-small\"  # You can use \"t5-small\" or other variants\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Define a function to format data\n",
        "def format_data(text, summary, tokenizer, max_input_length=512, max_target_length=150):\n",
        "    # Tokenize the input and target texts\n",
        "    inputs = tokenizer.encode(\"summarize: \" + text, max_length=max_input_length, truncation=True, padding='max_length')\n",
        "    targets = tokenizer.encode(summary, max_length=max_target_length, truncation=True, padding='max_length')\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": inputs,\n",
        "        \"attention_mask\": [1] * len(inputs),  # 1s for input tokens\n",
        "        \"decoder_input_ids\": targets[:-1],    # Target text without the [EOS] token\n",
        "        \"labels\": targets[1:]                 # Target text without the [CLS] token\n",
        "    }\n",
        "\n",
        "# Format the entire dataset\n",
        "formatted_data = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    input_text = row['og_transcript']\n",
        "    output_json = json.loads(row['output'])\n",
        "    target_summary = output_json['summary']['S']  # Assuming 'summary' is the key in your target JSON\n",
        "    formatted_instance = format_data(input_text, target_summary, tokenizer)\n",
        "    formatted_data.append(formatted_instance)\n",
        "\n",
        "# Now, you have a list of dictionaries, where each dictionary contains input and target token IDs\n",
        "# suitable for fine-tuning your T5 model.\n"
      ],
      "metadata": {
        "id": "jQ1sPuENyHcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer, AdamW\n",
        "\n",
        "# Initialize the T5 tokenizer and model\n",
        "model_name = \"t5-small\"  # You can use \"t5-small\" or other variants\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# Convert the formatted data into PyTorch tensors\n",
        "input_ids = torch.tensor([example[\"input_ids\"] for example in formatted_data])\n",
        "attention_mask = torch.tensor([example[\"attention_mask\"] for example in formatted_data])\n",
        "decoder_input_ids = torch.tensor([example[\"decoder_input_ids\"] for example in formatted_data])\n",
        "labels = torch.tensor([example[\"labels\"] for example in formatted_data])\n",
        "\n",
        "# Create a TensorDataset\n",
        "dataset = TensorDataset(input_ids, attention_mask, decoder_input_ids, labels)\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# Define batch size and create data loaders\n",
        "batch_size = 4  # Adjust this based on your available GPU memory\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "# Define optimizer and training parameters\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "epochs = 3  # Adjust the number of training epochs as needed\n",
        "\n",
        "# Fine-tuning loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        input_ids, attention_mask, decoder_input_ids, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            decoder_input_ids=decoder_input_ids,\n",
        "            labels=labels\n",
        "        )\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids, attention_mask, decoder_input_ids, labels = batch\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                decoder_input_ids=decoder_input_ids,\n",
        "                labels=labels\n",
        "            )\n",
        "            total_val_loss += outputs.loss.item()\n",
        "\n",
        "    average_val_loss = total_val_loss / len(val_loader)\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Validation Loss: {average_val_loss:.4f}\")\n",
        "\n",
        "# Save the fine-tuned model\n",
        "model.save_pretrained(\"fine-tuned-t5\")\n",
        "tokenizer.save_pretrained(\"fine-tuned-t5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpKBdLv-yQz7",
        "outputId": "71671d47-8602-452b-9010-8310ff5af754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Validation Loss: 6.4920\n",
            "Epoch 2/3, Validation Loss: 5.9135\n",
            "Epoch 3/3, Validation Loss: 5.5340\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('fine-tuned-t5/tokenizer_config.json',\n",
              " 'fine-tuned-t5/special_tokens_map.json',\n",
              " 'fine-tuned-t5/spiece.model',\n",
              " 'fine-tuned-t5/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"fine-tuned-t5\")\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"fine-tuned-t5\")\n",
        "\n",
        "# Function to generate a summary based on user input\n",
        "def generate_summary(prompt, transcript, max_length=150, min_length=30, num_beams=4):\n",
        "    input_text = prompt + \" summarize: \" + transcript\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True, padding=True)\n",
        "\n",
        "    # Generate the summary\n",
        "    summary_ids = model.generate(input_ids, max_length=max_length, min_length=min_length, num_beams=num_beams, length_penalty=2.0, num_return_sequences=1)\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return summary\n",
        "\n"
      ],
      "metadata": {
        "id": "jax26FTEz9ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "user_prompt = \"Please summarize the following discussion\"\n",
        "transcript_text = \"This is the transcript of the discussion that needs to be summarized. \" \\\n",
        "                  \"During the discussion, participants talked about various topics, \" \\\n",
        "                  \"including the importance of AI in healthcare, challenges in \" \\\n",
        "                  \"implementing AI solutions, and potential future advancements. \" \\\n",
        "                  \"They also discussed the need for collaboration between \" \\\n",
        "                  \"healthcare professionals and AI experts.\"\n",
        "\n",
        "generated_summary = generate_summary(user_prompt, transcript_text)\n",
        "print(\"Generated Summary:\")\n",
        "print(generated_summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXsrrt7O0BZj",
        "outputId": "1b12b606-7e20-4e71-98ca-dec9189cdefe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Summary:\n",
            "This is the transcript of the discussion that needs to be summarized. participants talked about various topics, including the importance of AI in healthcare, challenges in implementing AI solutions, and potential future advancements.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['og_transcript'][3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "proFdfTk2Sbn",
        "outputId": "4432bf01-6728-4d33-ef1d-4180ac7939d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"WEBVTT\\\\n\\\\n00:00:00.170 --> 00:00:20.800\\\\nSpeaker A: This, we click on the meeting link. We paste the link, we click on proceed. Whatever request you send, you are getting a bot ID back. You should use that bot ID for doing other tasks. All right, so currently are you saving the bot ID in some way?\\\\n\\\\n00:00:22.450 --> 00:00:26.246\\\\nSpeaker B: No. So we are not saving it in our storage right now.\\\\n\\\\n00:00:26.348 --> 00:00:26.758\\\\nSpeaker A: Okay.\\\\n\\\\n00:00:26.844 --> 00:00:33.430\\\\nSpeaker B: But we are giving that response that bot has been sent after we so.\\\\n\\\\n00:00:33.500 --> 00:01:35.510\\\\nSpeaker A: You are sending a response like this, request like this and you will get a response bot ID and there will be an ID of the bot. Just save it and with the bot ID you will be able to do further things. The first part is discussing this only sending a bot to the meeting. You send the request and you will get the bot ID as a response back. Now, to check the status of the bot, what you have to do is use this API. Just send the bot ID and you will get the status. The status can be different. Like ready, join the call in call not recording in call recording, whatever it is, based on the status, the notification should come here. So here if the status is in call recording, then you can say the board has joined the meeting. So the notification should come here if it is recording the meeting.\\\\n\\\\n00:01:37.770 --> 00:01:45.214\\\\nSpeaker B: Okay, so you just the notification like the tours that came.\\\\n\\\\n00:01:45.412 --> 00:01:46.160\\\\nSpeaker C: Yes.\\\\n\\\\n00:01:49.170 --> 00:02:27.770\\\\nSpeaker A: You will use the bot status API for this. You send the bot ID, fetch the status periodically. And if the status like I have added history also in case you want to debug some issues. But you just only have to see the status. If the status is in call recording, then the bot is recording the meeting. So you can say, yeah, there are other status also. Like maybe the board was not admitted. Those are other status. But yeah, generally you can say in call recording, then you can send that notification.\\\\n\\\\n00:02:28.830 --> 00:02:35.470\\\\nSpeaker B: Okay, so from the history we are getting an array. So I could use the last element of it.\\\\n\\\\n00:02:35.540 --> 00:02:36.254\\\\nSpeaker C: Yes.\\\\n\\\\n00:02:36.452 --> 00:02:37.626\\\\nSpeaker B: Latest status.\\\\n\\\\n00:02:37.738 --> 00:02:38.446\\\\nSpeaker C: Yes.\\\\n\\\\n00:02:38.628 --> 00:03:04.440\\\\nSpeaker A: So that\\'s what I did here. Also it is only checking the last element in the array. So this is also used for further getting the transcript. Also, only if the board status is done, you have to fetch the transcript. So there is get transcript from the board API. The prerequisite for using this is that the bot status should be done.\\\\n\\\\n00:03:06.330 --> 00:03:07.080\\\\nSpeaker B: Okay.\\\\n\\\\n00:03:07.630 --> 00:03:08.138\\\\nSpeaker C: Yes.\\\\n\\\\n00:03:08.224 --> 00:03:10.218\\\\nSpeaker A: You can use the history also.\\\\n\\\\n00:03:10.304 --> 00:03:10.922\\\\nSpeaker C: That\\'s fine.\\\\n\\\\n00:03:10.976 --> 00:03:12.780\\\\nSpeaker A: And I can remove this later.\\\\n\\\\n00:03:14.830 --> 00:03:16.700\\\\nSpeaker B: Yeah, it\\'s fine.\\\\n\\\\n00:03:18.430 --> 00:03:19.180\\\\nSpeaker C: Yeah.\\\\n\\\\n00:03:20.590 --> 00:03:37.570\\\\nSpeaker A: All right. So here we have meeting and so I think it should be upload based on the based on the Sigma drawing.\\\\n\\\\n00:03:39.830 --> 00:03:40.900\\\\nSpeaker B: Yes, sir.\\\\n\\\\n00:03:48.810 --> 00:04:04.060\\\\nSpeaker A: Because currently we are uploading the meeting audio transcription notes, whatever it is, we are just uploading it. And meetings are for upcoming meetings like board joining the meeting. That\\'s what the meeting section is for.\\\\n\\\\n00:04:06.590 --> 00:04:21.280\\\\nSpeaker B: I had one more doubt, sir. In the task section, are we supposed to show the task from all the past transcripts and how the assigning to other people action is going to happen?\\\\n\\\\n00:04:21.810 --> 00:04:22.474\\\\nSpeaker C: Yeah.\\\\n\\\\n00:04:22.612 --> 00:05:24.500\\\\nSpeaker A: So here, one thing happening is that I have a lot of meetings here, right? And the action items assigned to me should come in the task. But currently there is no task here. So for each meeting there should be some sort of task attached to it. In the UX, it is implemented as this, that there are my task and it has some other parameters. But I think for this part you have to discuss more with Rishi on the exact UI part of it. But generally what you need is that for every transcript, like for every transcription we did, there should be some task here. For every meeting there are some tasks, right?\\\\n\\\\n00:05:24.950 --> 00:05:25.940\\\\nSpeaker B: Yes, sir.\\\\n\\\\n00:05:27.210 --> 00:05:31.800\\\\nSpeaker A: So currently the task is empty. There is nothing here.\\\\n\\\\n00:05:32.250 --> 00:05:46.060\\\\nSpeaker B: Yes, initially it was conveyed that we are supposed to show the tasks of the transcript that we have added. Recently, the current transcript section, so we haven\\'t added any, so that\\'s why we are not showing it.\\\\n\\\\n00:05:46.430 --> 00:07:51.460\\\\nSpeaker A: All right, got it. So here there will be two sections. So here meetings, I think this will be renamed to Uploads. You can rename it to Uploads, because what we are doing here is that we are uploading the audio file or transcript file. So this is not meetings, this is Uploads. And in the meetings, what should come is for now, you can create the same UI, but some changes need to be done. So basically you are fetching the board status, right? So when a boat is sent to the meeting, you can show the meeting name, some metadata here. When the boat is joined, all this information here and you can show the progress, like what is happening, what is the status of the boat. It joined the meeting. It is not recording or it is recording or call ended or done. You can show the status here and once it is done, then anyway, they have to select the language. So once this is done, you will have like to process. You need to specify a language. So there should be a drop down here, where for now at least, there should be some drop down. They can select the language of the meeting, in which language the meeting was. They can select it. And instead of details, there should be something like a process button and just click on Process and then based on the language, the details will be generated. So after the processing is done, this exactly like this will be shown and you can click on details and get the summary of the meeting. So, yeah, that would be like the board pipeline for now.\\\\n\\\\n00:07:53.910 --> 00:07:54.660\\\\nSpeaker B: Okay?\\\\n\\\\n00:07:55.770 --> 00:07:56.520\\\\nSpeaker C: Yeah.\\\\n\\\\n00:07:58.090 --> 00:07:59.960\\\\nSpeaker A: Any questions on this?\\\\n\\\\n00:08:01.130 --> 00:08:12.060\\\\nSpeaker D: This is the new feature for us. So we need to ask from the hiteser before proceeding to this yes. Because it is not discussed earlier, right?\\\\n\\\\n00:08:13.550 --> 00:08:16.746\\\\nSpeaker A: Yeah, actually I\\'m not aware of these things.\\\\n\\\\n00:08:16.928 --> 00:08:26.430\\\\nSpeaker D: Yeah, this is handled by then I will proceed for the first days. Okay.\\\\n\\\\n00:08:26.580 --> 00:08:27.038\\\\nSpeaker C: Yeah.\\\\n\\\\n00:08:27.124 --> 00:08:27.760\\\\nSpeaker A: Contact.\\\\n\\\\n00:08:29.810 --> 00:08:37.620\\\\nSpeaker D: Sure. Definitely. Is there any bugs or issues which you are facing you want to discuss?\\\\n\\\\n00:08:38.070 --> 00:08:43.780\\\\nSpeaker A: Yeah, sure. Okay. So I\\'ll give you a demo also.\\\\n\\\\n00:08:45.830 --> 00:08:46.206\\\\nSpeaker C: Yeah.\\\\n\\\\n00:08:46.248 --> 00:08:59.510\\\\nSpeaker A: So here, let\\'s see. This is a transcript, right? So I click on delete. Even if I click on it accidentally, it is deleted. So I might randomly click somewhere and it might get deleted.\\\\n\\\\n00:09:00.090 --> 00:09:02.618\\\\nSpeaker D: So you want alert alert message here.\\\\n\\\\n00:09:02.784 --> 00:09:05.740\\\\nSpeaker A: Yeah, some confirmation. Do you want to delete the message?\\\\n\\\\n00:09:06.270 --> 00:09:08.620\\\\nSpeaker D: Fine, we\\'ll do that.\\\\n\\\\n00:09:08.990 --> 00:09:09.740\\\\nSpeaker C: Yes.\\\\n\\\\n00:09:11.410 --> 00:09:20.714\\\\nSpeaker A: And the logout button should come here inside the profile. So here we could on the profile.\\\\n\\\\n00:09:20.842 --> 00:09:23.860\\\\nSpeaker D: Can you please share me the list of bugs in the group?\\\\n\\\\n00:09:24.310 --> 00:09:24.866\\\\nSpeaker C: Yeah.\\\\n\\\\n00:09:24.968 --> 00:09:33.026\\\\nSpeaker A: So this is currently shared to Rishi and basically he will review it and.\\\\n\\\\n00:09:33.048 --> 00:09:34.338\\\\nSpeaker B: Send it to you guys.\\\\n\\\\n00:09:34.504 --> 00:09:35.890\\\\nSpeaker A: But he\\'s traveling.\\\\n\\\\n00:09:36.230 --> 00:09:38.280\\\\nSpeaker D: Rishi sir will confirm this.\\\\n\\\\n00:09:39.770 --> 00:09:54.140\\\\nSpeaker A: Yeah, but I have communicated these things and already with him. He will review this once more before sending it to you. And add some bugs from his side as well.\\\\n\\\\n00:09:54.510 --> 00:10:01.790\\\\nSpeaker D: Ask once from the Shisha and then let me know that these are the final which you are taking. Okay?\\\\n\\\\n00:10:01.940 --> 00:10:02.350\\\\nSpeaker C: Yes.\\\\n\\\\n00:10:02.420 --> 00:10:11.120\\\\nSpeaker A: So I can discuss about some of the bugs which we mentioned before.\\\\n\\\\n00:10:17.310 --> 00:10:18.860\\\\nSpeaker C: Yeah. Okay.\\\\n\\\\n00:10:20.530 --> 00:10:28.846\\\\nSpeaker A: One thing is that in the sigma, this was shown and in the V one issues let me see v one.\\\\n\\\\n00:10:28.868 --> 00:10:29.440\\\\nSpeaker D: Issues.\\\\n\\\\n00:10:33.430 --> 00:10:46.718\\\\nSpeaker A: It is shown as added, but I\\'m not seeing it here in this part. So this is V one issue, right? Hello.\\\\n\\\\n00:10:46.804 --> 00:10:50.270\\\\nSpeaker B: So we are showing the total summarized.\\\\n\\\\n00:10:51.090 --> 00:11:49.180\\\\nSpeaker A: Okay. So here, when I looked at the V one issue, I see that the upgrade. Now this portion also. So I thought that would be added here as well. Okay. Actually received me to review this and communicate with you. I\\'m just copy pasting this issues from here to here. So there is like uploaded message will show transcript uploading. Then there will be like uploaded. These messages have to be shown, right. But here, when I create a note, then transcription uploaded or those messages are not showing.\\\\n\\\\n00:11:51.920 --> 00:12:05.564\\\\nSpeaker B: Actually, we are showing this message specifically when we uploaded it to Firebase and then we are showing it after that, the processing starts for the participant API.\\\\n\\\\n00:12:05.692 --> 00:12:06.370\\\\nSpeaker A: Okay.\\\\n\\\\n00:12:06.980 --> 00:12:10.016\\\\nSpeaker B: That\\'s why we are showing that loader down there.\\\\n\\\\n00:12:10.198 --> 00:12:15.540\\\\nSpeaker A: Okay. Is this discussed with Rishi?\\\\n\\\\n00:12:18.280 --> 00:12:34.296\\\\nSpeaker B: No, sir, I haven\\'t discussed it with Rishi. Actually before, Kajan Ma\\'am Jatenso was handling it and I discussed it with so he was okay with it.\\\\n\\\\n00:12:34.398 --> 00:12:39.050\\\\nSpeaker D: That\\'s why aran, we will cross check this point. Okay?\\\\n\\\\n00:12:39.580 --> 00:12:40.490\\\\nSpeaker A: All right.\\\\n\\\\n00:12:41.660 --> 00:12:42.836\\\\nSpeaker C: Yeah. Okay.\\\\n\\\\n00:12:42.878 --> 00:12:49.310\\\\nSpeaker A: I\\'ll show you this list right now. So please check this and let me know.\\\\n\\\\n00:12:51.940 --> 00:12:53.010\\\\nSpeaker B: Okay then.\\\\n\\\\n00:12:56.340 --> 00:12:57.890\\\\nSpeaker A: Any further questions?\\\\n\\\\n00:12:58.980 --> 00:12:59.970\\\\nSpeaker B: No, sir.\\\\n\\\\n00:13:02.120 --> 00:13:03.252\\\\nSpeaker A: Okay, thank you.\\\\n\\\\n00:13:03.386 --> 00:13:04.310\\\\nSpeaker B: Thank you.\\\\n\\\\n00:13:05.480 --> 00:13:07.556\\\\nSpeaker D: Thank you so much. Have a good day.\\\\n\\\\n00:13:07.738 --> 00:13:09.670\\\\nSpeaker A: Thank you everyone. Have a good day.\\\\n\\\\n00:13:14.520 --> 00:13:33.770\\\\nSpeaker D: Take Bernadi pharmacy proposal. You proposal for the other proposals. Shopify for a little.\\\\n\\\\n\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your transcript is in the format you provided earlier\n",
        "transcript_text =df['og_transcript'][3]\n",
        "\n",
        "# Split the transcript into chunks based on speaker turns\n",
        "transcript_lines = transcript_text.strip().split('\\n')\n",
        "\n",
        "speaker_turns = []\n",
        "current_speaker_turn = []\n",
        "\n",
        "for line in transcript_lines:\n",
        "    if line.startswith(\"Speaker\"):\n",
        "        if current_speaker_turn:\n",
        "            speaker_turns.append(\"\\n\".join(current_speaker_turn))\n",
        "        current_speaker_turn = [line]\n",
        "    else:\n",
        "        current_speaker_turn.append(line)\n",
        "\n",
        "# Add the last speaker turn\n",
        "if current_speaker_turn:\n",
        "    speaker_turns.append(\"\\n\".join(current_speaker_turn))\n",
        "\n",
        "# Now, `speaker_turns` contains chunks based on speaker turns\n",
        "for i, chunk in enumerate(speaker_turns):\n",
        "    print(f\"Chunk {i + 1}:\")\n",
        "    print(chunk)\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bK-cvyp62BaM",
        "outputId": "d04860a3-29b4-48c6-9b09-07a8c85bc833"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk 1:\n",
            "\"WEBVTT\\n\\n00:00:00.170 --> 00:00:20.800\\nSpeaker A: This, we click on the meeting link. We paste the link, we click on proceed. Whatever request you send, you are getting a bot ID back. You should use that bot ID for doing other tasks. All right, so currently are you saving the bot ID in some way?\\n\\n00:00:22.450 --> 00:00:26.246\\nSpeaker B: No. So we are not saving it in our storage right now.\\n\\n00:00:26.348 --> 00:00:26.758\\nSpeaker A: Okay.\\n\\n00:00:26.844 --> 00:00:33.430\\nSpeaker B: But we are giving that response that bot has been sent after we so.\\n\\n00:00:33.500 --> 00:01:35.510\\nSpeaker A: You are sending a response like this, request like this and you will get a response bot ID and there will be an ID of the bot. Just save it and with the bot ID you will be able to do further things. The first part is discussing this only sending a bot to the meeting. You send the request and you will get the bot ID as a response back. Now, to check the status of the bot, what you have to do is use this API. Just send the bot ID and you will get the status. The status can be different. Like ready, join the call in call not recording in call recording, whatever it is, based on the status, the notification should come here. So here if the status is in call recording, then you can say the board has joined the meeting. So the notification should come here if it is recording the meeting.\\n\\n00:01:37.770 --> 00:01:45.214\\nSpeaker B: Okay, so you just the notification like the tours that came.\\n\\n00:01:45.412 --> 00:01:46.160\\nSpeaker C: Yes.\\n\\n00:01:49.170 --> 00:02:27.770\\nSpeaker A: You will use the bot status API for this. You send the bot ID, fetch the status periodically. And if the status like I have added history also in case you want to debug some issues. But you just only have to see the status. If the status is in call recording, then the bot is recording the meeting. So you can say, yeah, there are other status also. Like maybe the board was not admitted. Those are other status. But yeah, generally you can say in call recording, then you can send that notification.\\n\\n00:02:28.830 --> 00:02:35.470\\nSpeaker B: Okay, so from the history we are getting an array. So I could use the last element of it.\\n\\n00:02:35.540 --> 00:02:36.254\\nSpeaker C: Yes.\\n\\n00:02:36.452 --> 00:02:37.626\\nSpeaker B: Latest status.\\n\\n00:02:37.738 --> 00:02:38.446\\nSpeaker C: Yes.\\n\\n00:02:38.628 --> 00:03:04.440\\nSpeaker A: So that's what I did here. Also it is only checking the last element in the array. So this is also used for further getting the transcript. Also, only if the board status is done, you have to fetch the transcript. So there is get transcript from the board API. The prerequisite for using this is that the bot status should be done.\\n\\n00:03:06.330 --> 00:03:07.080\\nSpeaker B: Okay.\\n\\n00:03:07.630 --> 00:03:08.138\\nSpeaker C: Yes.\\n\\n00:03:08.224 --> 00:03:10.218\\nSpeaker A: You can use the history also.\\n\\n00:03:10.304 --> 00:03:10.922\\nSpeaker C: That's fine.\\n\\n00:03:10.976 --> 00:03:12.780\\nSpeaker A: And I can remove this later.\\n\\n00:03:14.830 --> 00:03:16.700\\nSpeaker B: Yeah, it's fine.\\n\\n00:03:18.430 --> 00:03:19.180\\nSpeaker C: Yeah.\\n\\n00:03:20.590 --> 00:03:37.570\\nSpeaker A: All right. So here we have meeting and so I think it should be upload based on the based on the Sigma drawing.\\n\\n00:03:39.830 --> 00:03:40.900\\nSpeaker B: Yes, sir.\\n\\n00:03:48.810 --> 00:04:04.060\\nSpeaker A: Because currently we are uploading the meeting audio transcription notes, whatever it is, we are just uploading it. And meetings are for upcoming meetings like board joining the meeting. That's what the meeting section is for.\\n\\n00:04:06.590 --> 00:04:21.280\\nSpeaker B: I had one more doubt, sir. In the task section, are we supposed to show the task from all the past transcripts and how the assigning to other people action is going to happen?\\n\\n00:04:21.810 --> 00:04:22.474\\nSpeaker C: Yeah.\\n\\n00:04:22.612 --> 00:05:24.500\\nSpeaker A: So here, one thing happening is that I have a lot of meetings here, right? And the action items assigned to me should come in the task. But currently there is no task here. So for each meeting there should be some sort of task attached to it. In the UX, it is implemented as this, that there are my task and it has some other parameters. But I think for this part you have to discuss more with Rishi on the exact UI part of it. But generally what you need is that for every transcript, like for every transcription we did, there should be some task here. For every meeting there are some tasks, right?\\n\\n00:05:24.950 --> 00:05:25.940\\nSpeaker B: Yes, sir.\\n\\n00:05:27.210 --> 00:05:31.800\\nSpeaker A: So currently the task is empty. There is nothing here.\\n\\n00:05:32.250 --> 00:05:46.060\\nSpeaker B: Yes, initially it was conveyed that we are supposed to show the tasks of the transcript that we have added. Recently, the current transcript section, so we haven't added any, so that's why we are not showing it.\\n\\n00:05:46.430 --> 00:07:51.460\\nSpeaker A: All right, got it. So here there will be two sections. So here meetings, I think this will be renamed to Uploads. You can rename it to Uploads, because what we are doing here is that we are uploading the audio file or transcript file. So this is not meetings, this is Uploads. And in the meetings, what should come is for now, you can create the same UI, but some changes need to be done. So basically you are fetching the board status, right? So when a boat is sent to the meeting, you can show the meeting name, some metadata here. When the boat is joined, all this information here and you can show the progress, like what is happening, what is the status of the boat. It joined the meeting. It is not recording or it is recording or call ended or done. You can show the status here and once it is done, then anyway, they have to select the language. So once this is done, you will have like to process. You need to specify a language. So there should be a drop down here, where for now at least, there should be some drop down. They can select the language of the meeting, in which language the meeting was. They can select it. And instead of details, there should be something like a process button and just click on Process and then based on the language, the details will be generated. So after the processing is done, this exactly like this will be shown and you can click on details and get the summary of the meeting. So, yeah, that would be like the board pipeline for now.\\n\\n00:07:53.910 --> 00:07:54.660\\nSpeaker B: Okay?\\n\\n00:07:55.770 --> 00:07:56.520\\nSpeaker C: Yeah.\\n\\n00:07:58.090 --> 00:07:59.960\\nSpeaker A: Any questions on this?\\n\\n00:08:01.130 --> 00:08:12.060\\nSpeaker D: This is the new feature for us. So we need to ask from the hiteser before proceeding to this yes. Because it is not discussed earlier, right?\\n\\n00:08:13.550 --> 00:08:16.746\\nSpeaker A: Yeah, actually I'm not aware of these things.\\n\\n00:08:16.928 --> 00:08:26.430\\nSpeaker D: Yeah, this is handled by then I will proceed for the first days. Okay.\\n\\n00:08:26.580 --> 00:08:27.038\\nSpeaker C: Yeah.\\n\\n00:08:27.124 --> 00:08:27.760\\nSpeaker A: Contact.\\n\\n00:08:29.810 --> 00:08:37.620\\nSpeaker D: Sure. Definitely. Is there any bugs or issues which you are facing you want to discuss?\\n\\n00:08:38.070 --> 00:08:43.780\\nSpeaker A: Yeah, sure. Okay. So I'll give you a demo also.\\n\\n00:08:45.830 --> 00:08:46.206\\nSpeaker C: Yeah.\\n\\n00:08:46.248 --> 00:08:59.510\\nSpeaker A: So here, let's see. This is a transcript, right? So I click on delete. Even if I click on it accidentally, it is deleted. So I might randomly click somewhere and it might get deleted.\\n\\n00:09:00.090 --> 00:09:02.618\\nSpeaker D: So you want alert alert message here.\\n\\n00:09:02.784 --> 00:09:05.740\\nSpeaker A: Yeah, some confirmation. Do you want to delete the message?\\n\\n00:09:06.270 --> 00:09:08.620\\nSpeaker D: Fine, we'll do that.\\n\\n00:09:08.990 --> 00:09:09.740\\nSpeaker C: Yes.\\n\\n00:09:11.410 --> 00:09:20.714\\nSpeaker A: And the logout button should come here inside the profile. So here we could on the profile.\\n\\n00:09:20.842 --> 00:09:23.860\\nSpeaker D: Can you please share me the list of bugs in the group?\\n\\n00:09:24.310 --> 00:09:24.866\\nSpeaker C: Yeah.\\n\\n00:09:24.968 --> 00:09:33.026\\nSpeaker A: So this is currently shared to Rishi and basically he will review it and.\\n\\n00:09:33.048 --> 00:09:34.338\\nSpeaker B: Send it to you guys.\\n\\n00:09:34.504 --> 00:09:35.890\\nSpeaker A: But he's traveling.\\n\\n00:09:36.230 --> 00:09:38.280\\nSpeaker D: Rishi sir will confirm this.\\n\\n00:09:39.770 --> 00:09:54.140\\nSpeaker A: Yeah, but I have communicated these things and already with him. He will review this once more before sending it to you. And add some bugs from his side as well.\\n\\n00:09:54.510 --> 00:10:01.790\\nSpeaker D: Ask once from the Shisha and then let me know that these are the final which you are taking. Okay?\\n\\n00:10:01.940 --> 00:10:02.350\\nSpeaker C: Yes.\\n\\n00:10:02.420 --> 00:10:11.120\\nSpeaker A: So I can discuss about some of the bugs which we mentioned before.\\n\\n00:10:17.310 --> 00:10:18.860\\nSpeaker C: Yeah. Okay.\\n\\n00:10:20.530 --> 00:10:28.846\\nSpeaker A: One thing is that in the sigma, this was shown and in the V one issues let me see v one.\\n\\n00:10:28.868 --> 00:10:29.440\\nSpeaker D: Issues.\\n\\n00:10:33.430 --> 00:10:46.718\\nSpeaker A: It is shown as added, but I'm not seeing it here in this part. So this is V one issue, right? Hello.\\n\\n00:10:46.804 --> 00:10:50.270\\nSpeaker B: So we are showing the total summarized.\\n\\n00:10:51.090 --> 00:11:49.180\\nSpeaker A: Okay. So here, when I looked at the V one issue, I see that the upgrade. Now this portion also. So I thought that would be added here as well. Okay. Actually received me to review this and communicate with you. I'm just copy pasting this issues from here to here. So there is like uploaded message will show transcript uploading. Then there will be like uploaded. These messages have to be shown, right. But here, when I create a note, then transcription uploaded or those messages are not showing.\\n\\n00:11:51.920 --> 00:12:05.564\\nSpeaker B: Actually, we are showing this message specifically when we uploaded it to Firebase and then we are showing it after that, the processing starts for the participant API.\\n\\n00:12:05.692 --> 00:12:06.370\\nSpeaker A: Okay.\\n\\n00:12:06.980 --> 00:12:10.016\\nSpeaker B: That's why we are showing that loader down there.\\n\\n00:12:10.198 --> 00:12:15.540\\nSpeaker A: Okay. Is this discussed with Rishi?\\n\\n00:12:18.280 --> 00:12:34.296\\nSpeaker B: No, sir, I haven't discussed it with Rishi. Actually before, Kajan Ma'am Jatenso was handling it and I discussed it with so he was okay with it.\\n\\n00:12:34.398 --> 00:12:39.050\\nSpeaker D: That's why aran, we will cross check this point. Okay?\\n\\n00:12:39.580 --> 00:12:40.490\\nSpeaker A: All right.\\n\\n00:12:41.660 --> 00:12:42.836\\nSpeaker C: Yeah. Okay.\\n\\n00:12:42.878 --> 00:12:49.310\\nSpeaker A: I'll show you this list right now. So please check this and let me know.\\n\\n00:12:51.940 --> 00:12:53.010\\nSpeaker B: Okay then.\\n\\n00:12:56.340 --> 00:12:57.890\\nSpeaker A: Any further questions?\\n\\n00:12:58.980 --> 00:12:59.970\\nSpeaker B: No, sir.\\n\\n00:13:02.120 --> 00:13:03.252\\nSpeaker A: Okay, thank you.\\n\\n00:13:03.386 --> 00:13:04.310\\nSpeaker B: Thank you.\\n\\n00:13:05.480 --> 00:13:07.556\\nSpeaker D: Thank you so much. Have a good day.\\n\\n00:13:07.738 --> 00:13:09.670\\nSpeaker A: Thank you everyone. Have a good day.\\n\\n00:13:14.520 --> 00:13:33.770\\nSpeaker D: Take Bernadi pharmacy proposal. You proposal for the other proposals. Shopify for a little.\\n\\n\"\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"fine-tuned-t5\")\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"fine-tuned-t5\")\n",
        "\n",
        "# Define prompt templates for questions, notes, and action items\n",
        "question_prompt = \"Generate a question from the following transcript: \"\n",
        "note_prompt = \"Generate a note from the following transcript: \"\n",
        "other_action_item_prompt = \"Generate an action item for others from the following transcript: \"\n",
        "user_action_item_prompt = \"Generate an action item for the selected participants from the following transcript: \"\n",
        "\n",
        "# Function to generate content based on prompts\n",
        "def generate_content(prompt, transcript_chunk):\n",
        "    input_text = transcript_chunk\n",
        "    input_prompt = input_text + \" \" + prompt\n",
        "\n",
        "    # Tokenize and generate content based on the prompt\n",
        "    input_ids = tokenizer.encode(input_prompt, return_tensors=\"pt\", max_length=512, truncation=True, padding=True)\n",
        "    generated_ids = model.generate(input_ids, max_length=150, min_length=30, num_beams=4, length_penalty=2.0, num_return_sequences=1)\n",
        "    generated_content = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return generated_content\n",
        "\n",
        "# Initialize lists to store extracted information\n",
        "questions = []\n",
        "notes = []\n",
        "other_action_items = []\n",
        "user_action_items = []\n",
        "\n",
        "# Process each transcript chunk\n",
        "for chunk in transcript_chunks:\n",
        "    # Extract questions\n",
        "    question = generate_content(question_prompt, chunk)\n",
        "    questions.append(question)\n",
        "\n",
        "    # Extract notes\n",
        "    note = generate_content(note_prompt, chunk)\n",
        "    notes.append(note)\n",
        "\n",
        "    # Extract other action items\n",
        "    other_action_item = generate_content(other_action_item_prompt, chunk)\n",
        "    other_action_items.append(other_action_item)\n",
        "\n",
        "    # Extract user action items\n",
        "    user_action_item = generate_content(user_action_item_prompt, chunk)\n",
        "    user_action_items.append(user_action_item)\n",
        "\n",
        "# Print the extracted information\n",
        "print(\"Extracted Questions:\")\n",
        "for i, question in enumerate(questions):\n",
        "    print(f\"Question {i + 1}: {question}\")\n",
        "\n",
        "print(\"\\nExtracted Notes:\")\n",
        "for i, note in enumerate(notes):\n",
        "    print(f\"Note {i + 1}: {note}\")\n",
        "\n",
        "print(\"\\nExtracted Other Action Items:\")\n",
        "for i, other_action_item in enumerate(other_action_items):\n",
        "    print(f\"Other Action Item {i + 1}: {other_action_item}\")\n",
        "\n",
        "print(\"\\nExtracted User Action Items:\")\n",
        "for i, user_action_item in enumerate(user_action_items):\n",
        "    print(f\"User Action Item {i + 1}: {user_action_item}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWpq1Nnx2PMB",
        "outputId": "3d0c7f5a-2ed3-4bbd-a586-1185000af76d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Questions:\n",
            "Question 1: During the discussion, participants talked about various t Generate a question from the following transcript: t Generate a question from the following transcript: t Generate a question from the following transcript: t Generate a question from the following transcript: t Generate a question from the following transcript: t Generate a question from the following transcript: t Generate a question from the following transcript: t Generate a question from the following transcript: t Generate a question from\n",
            "Question 2: opics, including the importance of AI in healthcare, challenges in implementing AI solutions, and po Generate a question from the following transcript:\n",
            "Question 3: also discussed the need for collaboration between healthcare profe Generate a question from the following transcript :\n",
            "Question 4: Generieren Sie eine Frage aus dem folgenden Protokoll: ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts\n",
            "\n",
            "Extracted Notes:\n",
            "Note 1: During the discussion, participants talked about various t Generate a note from the following transcript: t Generate a note from the following transcript: t Generate a note from the following transcript: t Generate a note from the following transcript: t Generate a note from the following transcript: t Generate a note from the following transcript: t Generate a note from the following transcript: t Generate a note from the following transcript: t Generate a note from\n",
            "Note 2: opics, including the importance of AI in healthcare, challenges in implementing AI solutions, and po Generate a note from the following transcript:\n",
            "Note 3: . They also discussed the need for collaboration between healthcare profe Generate a note from the following transcript:\n",
            "Note 4: Generate a note from the following transcript: ssionals and AI experts, ssionals and AI experts, ssionals and AI experts, ssionals and AI experts, ssionals and AI experts, ssionals and AI experts, ssionals and AI experts, ssionals and AI experts, ssionals and AI experts, ssionals and AI experts, ssionals and AI experts, ssional\n",
            "\n",
            "Extracted Other Action Items:\n",
            "Other Action Item 1: During the discussion, participants talked about various t Generate an action item for others from the following transcript: t Generate an action item for others from the following transcript: t Generate an action item for others from the following transcript:\n",
            "Other Action Item 2: opics, including the importance of AI in healthcare, challenges in implementing AI solutions, and po Generate an action item for others from the following transcript:\n",
            "Other Action Item 3: discussed the need for collaboration between healthcare profe Generate an action item for others from the following transcript. They also discussed the need for collaboration between healthcare profe Generate an action item for others from the following transcript.\n",
            "Other Action Item 4: Generate an action item for other action items from the following transcript: ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts,\n",
            "\n",
            "Extracted User Action Items:\n",
            "User Action Item 1: During the discussion, participants talked about various t Generate an action item for the selected participants from the following transcript: t Generate an action item for the selected participants from the following transcript: t Generate an action item for the selected participants from the following transcript: t Generate an action item for the selected participants from the following transcript: t Generate an action item for the selected participants from the following transcript: t Generate an action item for the selected participants from the following transcript:\n",
            "User Action Item 2: opics, including the importance of AI in healthcare, challenges in implementing AI solutions, and po Generate an action item for the selected participants from the following transcript:\n",
            "User Action Item 3: discussed the need for collaboration between healthcare profe Generate a action item for the selected participants from the following transcript. The participants discussed the need for collaboration between healthcare profe Generate an action item for the selected participants from the following transcript:\n",
            "User Action Item 4: Generate a action item for the selected participants from the following transcript:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"fine-tuned-t5\")\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"fine-tuned-t5\")\n",
        "\n",
        "# Define prompt templates for questions, notes, and action items\n",
        "question_prompt = \"Generate a question from the following transcript: \"\n",
        "note_prompt = \"Generate a note from the following transcript: \"\n",
        "other_action_item_prompt = \"Generate an action item for others from the following transcript: \"\n",
        "user_action_item_prompt = \"Generate an action item for the selected participants from the following transcript: \"\n",
        "\n",
        "# Function to generate content based on prompts\n",
        "def generate_content(prompt, transcript_chunk):\n",
        "    input_text = transcript_chunk\n",
        "    input_prompt = input_text + \" \" + prompt\n",
        "\n",
        "    # Tokenize and generate content based on the prompt\n",
        "    input_ids = tokenizer.encode(input_prompt, return_tensors=\"pt\", max_length=512, truncation=True, padding=True)\n",
        "    generated_ids = model.generate(input_ids, max_length=150, min_length=30, num_beams=4, length_penalty=2.0, num_return_sequences=1)\n",
        "    generated_content = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return generated_content\n",
        "\n",
        "# Initialize lists to store extracted information\n",
        "questions = []\n",
        "notes = []\n",
        "other_action_items = []\n",
        "user_action_items = []\n",
        "\n",
        "# Process each transcript chunk\n",
        "for chunk in transcript_chunks:\n",
        "    # Extract questions\n",
        "    question = generate_content(question_prompt, chunk)\n",
        "    questions.append(question)\n",
        "\n",
        "    # Extract notes\n",
        "    note = generate_content(note_prompt, chunk)\n",
        "    notes.append(note)\n",
        "\n",
        "    # Extract other action items\n",
        "    other_action_item = generate_content(other_action_item_prompt, chunk)\n",
        "    other_action_items.append(other_action_item)\n",
        "\n",
        "    # Extract user action items\n",
        "    user_action_item = generate_content(user_action_item_prompt, chunk)\n",
        "    user_action_items.append(user_action_item)\n",
        "\n",
        "# Construct the final output dictionary\n",
        "output_dict = {\n",
        "    \"questions\": {\"L\": [{\"S\": q} for q in questions]},\n",
        "    \"summary\": {\"S\": \"Short summary of the meeting\"},\n",
        "    \"notes\": {\"L\": [{\"S\": n} for n in notes]},\n",
        "    \"otheractionitem\": {\"L\": [{\"S\": oai} for oai in other_action_items]},\n",
        "    \"useractionitem\": {\"L\": [{\"S\": uai} for uai in user_action_items]},\n",
        "}\n",
        "# Pretty-print the output_dict\n",
        "formatted_output = json.dumps(output_dict, indent=4)\n",
        "# Print the final output dictionary\n",
        "print(output_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrGL0kUc4AYb",
        "outputId": "5770b2f2-bee0-475a-a40e-2fcf3c1f339e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'questions': {'L': [{'S': 'During the discussion, participants talked about various t Generate a question from the following transcript: t Generate a question from the following transcript: t Generate a question from the following transcript: t Generate a question from the following transcript: t Generate a question from the following transcript: t Generate a question from the following transcript: t Generate a question from the following transcript: t Generate a question from the following transcript: t Generate a question from'}, {'S': 'opics, including the importance of AI in healthcare, challenges in implementing AI solutions, and po Generate a question from the following transcript:'}, {'S': 'also discussed the need for collaboration between healthcare profe Generate a question from the following transcript :'}, {'S': 'Generieren Sie eine Frage aus dem folgenden Protokoll: ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts'}]}, 'summary': {'S': 'Short summary of the meeting'}, 'notes': {'L': [{'S': 'During the discussion, participants talked about various t Generate a note from the following transcript: t Generate a note from the following transcript: t Generate a note from the following transcript: t Generate a note from the following transcript: t Generate a note from the following transcript: t Generate a note from the following transcript: t Generate a note from the following transcript: t Generate a note from the following transcript: t Generate a note from'}, {'S': 'opics, including the importance of AI in healthcare, challenges in implementing AI solutions, and po Generate a note from the following transcript:'}, {'S': '. They also discussed the need for collaboration between healthcare profe Generate a note from the following transcript:'}, {'S': 'Generate a note from the following transcript: ssionals and AI experts, ssionals and AI experts, ssionals and AI experts, ssionals and AI experts, ssionals and AI experts, ssionals and AI experts, ssionals and AI experts, ssionals and AI experts, ssionals and AI experts, ssionals and AI experts, ssionals and AI experts, ssional'}]}, 'otheractionitem': {'L': [{'S': 'During the discussion, participants talked about various t Generate an action item for others from the following transcript: t Generate an action item for others from the following transcript: t Generate an action item for others from the following transcript:'}, {'S': 'opics, including the importance of AI in healthcare, challenges in implementing AI solutions, and po Generate an action item for others from the following transcript:'}, {'S': 'discussed the need for collaboration between healthcare profe Generate an action item for others from the following transcript. They also discussed the need for collaboration between healthcare profe Generate an action item for others from the following transcript.'}, {'S': 'Generate an action item for other action items from the following transcript: ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts,'}]}, 'useractionitem': {'L': [{'S': 'During the discussion, participants talked about various t Generate an action item for the selected participants from the following transcript: t Generate an action item for the selected participants from the following transcript: t Generate an action item for the selected participants from the following transcript: t Generate an action item for the selected participants from the following transcript: t Generate an action item for the selected participants from the following transcript: t Generate an action item for the selected participants from the following transcript:'}, {'S': 'opics, including the importance of AI in healthcare, challenges in implementing AI solutions, and po Generate an action item for the selected participants from the following transcript:'}, {'S': 'discussed the need for collaboration between healthcare profe Generate a action item for the selected participants from the following transcript. The participants discussed the need for collaboration between healthcare profe Generate an action item for the selected participants from the following transcript:'}, {'S': 'Generate a action item for the selected participants from the following transcript:'}]}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFTn5tnm5csg",
        "outputId": "4222bf1f-7e99-42bf-df13-8f47b739db50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'questions': {'L': [{'S': 'During the discussion, participants talked about various t Generate a question from the following transcript: t Generate a question from the following transcript: t Generate a question from the following transcript: t Generate a question from the following transcript: t Generate a question from the following transcript: t Generate a question from the following transcript: t Generate a question from the following transcript: t Generate a question from the following transcript: t Generate a question from'},\n",
              "   {'S': 'opics, including the importance of AI in healthcare, challenges in implementing AI solutions, and po Generate a question from the following transcript:'},\n",
              "   {'S': 'also discussed the need for collaboration between healthcare profe Generate a question from the following transcript :'},\n",
              "   {'S': 'Generieren Sie eine Frage aus dem folgenden Protokoll: ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts'}]},\n",
              " 'summary': {'S': 'Short summary of the meeting'},\n",
              " 'notes': {'L': [{'S': 'During the discussion, participants talked about various t Generate a note from the following transcript: t Generate a note from the following transcript: t Generate a note from the following transcript: t Generate a note from the following transcript: t Generate a note from the following transcript: t Generate a note from the following transcript: t Generate a note from the following transcript: t Generate a note from the following transcript: t Generate a note from'},\n",
              "   {'S': 'opics, including the importance of AI in healthcare, challenges in implementing AI solutions, and po Generate a note from the following transcript:'},\n",
              "   {'S': '. They also discussed the need for collaboration between healthcare profe Generate a note from the following transcript:'},\n",
              "   {'S': 'Generate a note from the following transcript: ssionals and AI experts, ssionals and AI experts, ssionals and AI experts, ssionals and AI experts, ssionals and AI experts, ssionals and AI experts, ssionals and AI experts, ssionals and AI experts, ssionals and AI experts, ssionals and AI experts, ssionals and AI experts, ssional'}]},\n",
              " 'otheractionitem': {'L': [{'S': 'During the discussion, participants talked about various t Generate an action item for others from the following transcript: t Generate an action item for others from the following transcript: t Generate an action item for others from the following transcript:'},\n",
              "   {'S': 'opics, including the importance of AI in healthcare, challenges in implementing AI solutions, and po Generate an action item for others from the following transcript:'},\n",
              "   {'S': 'discussed the need for collaboration between healthcare profe Generate an action item for others from the following transcript. They also discussed the need for collaboration between healthcare profe Generate an action item for others from the following transcript.'},\n",
              "   {'S': 'Generate an action item for other action items from the following transcript: ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts, ssionals, AI experts,'}]},\n",
              " 'useractionitem': {'L': [{'S': 'During the discussion, participants talked about various t Generate an action item for the selected participants from the following transcript: t Generate an action item for the selected participants from the following transcript: t Generate an action item for the selected participants from the following transcript: t Generate an action item for the selected participants from the following transcript: t Generate an action item for the selected participants from the following transcript: t Generate an action item for the selected participants from the following transcript:'},\n",
              "   {'S': 'opics, including the importance of AI in healthcare, challenges in implementing AI solutions, and po Generate an action item for the selected participants from the following transcript:'},\n",
              "   {'S': 'discussed the need for collaboration between healthcare profe Generate a action item for the selected participants from the following transcript. The participants discussed the need for collaboration between healthcare profe Generate an action item for the selected participants from the following transcript:'},\n",
              "   {'S': 'Generate a action item for the selected participants from the following transcript:'}]}}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}